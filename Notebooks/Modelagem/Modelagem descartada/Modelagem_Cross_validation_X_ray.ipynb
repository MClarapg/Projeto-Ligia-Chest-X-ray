{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWrAVR-Rbqdk"
      },
      "source": [
        "###Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D04yysl_pSdx"
      },
      "outputs": [],
      "source": [
        "# Importação básica\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6oUvJtIExkW7"
      },
      "outputs": [],
      "source": [
        "# Importações de visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Importação para visualização de imagem\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importação para carregar o Dataset\n",
        "import gdown\n",
        "import pickle\n",
        "import zipfile\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5RK-bEY4-XXO"
      },
      "outputs": [],
      "source": [
        "# Importação de preparação\n",
        "import random\n",
        "\n",
        "# Importação da Grad-Cam\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WH8HHKoQ_TgV"
      },
      "outputs": [],
      "source": [
        "# Importações de arquitetura\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "# Importação de validação\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k-INVua5cTF"
      },
      "source": [
        "###Carregamento de dataset e pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HlGRCZEA0d6C"
      },
      "outputs": [],
      "source": [
        "# Função de criação de dataframe\n",
        "def create_df(rows, path):\n",
        "    for label in [\"NORMAL\", \"PNEUMONIA\"]:\n",
        "        folder = os.path.join(path, label)\n",
        "\n",
        "        if not os.path.exists(folder):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(folder):\n",
        "            if filename.lower().endswith((\".jpeg\", \".jpg\", \".png\")):\n",
        "                rows.append({\n",
        "                    \"filepath\": os.path.join(folder, filename),\n",
        "                    \"filename\": filename,\n",
        "                    \"label\": label,\n",
        "                    \"label_bin\": 0 if label == \"NORMAL\" else 1,\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a932FNNeyQ9T",
        "outputId": "434652bb-8589-48dc-f860-b6705d012e9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IBC3mk83DnHkZ4Xn3Kq9H18kM3_WITx2\n",
            "From (redirected): https://drive.google.com/uc?id=1IBC3mk83DnHkZ4Xn3Kq9H18kM3_WITx2&confirm=t&uuid=3cb22d5d-7a28-4451-ab37-dfcc6fe159a3\n",
            "To: /content/chest_xray.zip\n",
            "100%|██████████| 1.26G/1.26G [00:20<00:00, 62.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset carregado!\n"
          ]
        }
      ],
      "source": [
        "# Este notebook é exclusivo para modelagem, logo o dataset será recarregado\n",
        "# Carregamento das imagens de teste\n",
        "file_test_id = \"1IBC3mk83DnHkZ4Xn3Kq9H18kM3_WITx2\"\n",
        "\n",
        "gdown.download(\n",
        "    f\"https://drive.google.com/uc?id={file_test_id}\",\n",
        "    \"/content/chest_xray.zip\",\n",
        "    quiet=False,\n",
        "    )\n",
        "\n",
        "with zipfile.ZipFile(\"/content/chest_xray.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/data_test\")\n",
        "\n",
        "print(\"Dataset carregado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSJ7xFKyPHBb",
        "outputId": "b9f17131-64fc-4804-8747-e61d00067a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 624 imagens\n",
            "label\n",
            "PNEUMONIA    390\n",
            "NORMAL       234\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Criação do dataframe de teste\n",
        "rows_test = []\n",
        "test_path = \"/content/data_test/chest_xray/test\"\n",
        "\n",
        "df_test = create_df(rows_test, test_path)\n",
        "print(f\"Treino: {len(df_test)} imagens\")\n",
        "print(df_test[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm0ZLC3LmyyL",
        "outputId": "0c3f32f0-55b3-4267-80ec-7eadf3ff15cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AGEiWDB7BaZA0qrTSsZOkMqM7fd9ru4e\n",
            "From (redirected): https://drive.google.com/uc?id=1AGEiWDB7BaZA0qrTSsZOkMqM7fd9ru4e&confirm=t&uuid=588430f9-5627-404a-bc46-c092acf7a4cd\n",
            "To: /content/chest_xray_tratado.zip\n",
            "100%|██████████| 40.3M/40.3M [00:00<00:00, 61.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset carregado!\n"
          ]
        }
      ],
      "source": [
        "# Carregamento das imagens de treino tratado\n",
        "file_train_id = \"1AGEiWDB7BaZA0qrTSsZOkMqM7fd9ru4e\"\n",
        "\n",
        "gdown.download(\n",
        "    f\"https://drive.google.com/uc?id={file_train_id}\",\n",
        "    \"/content/chest_xray_tratado.zip\",\n",
        "    quiet=False,\n",
        "    )\n",
        "\n",
        "with zipfile.ZipFile(\"/content/chest_xray_tratado.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/data_train_tratado\")\n",
        "\n",
        "print(\"Dataset carregado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-HOmSHwngG_",
        "outputId": "3a4bd2b4-b738-4ded-e5b3-bbd8446bb176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 5206 imagens\n",
            "label\n",
            "PNEUMONIA    3858\n",
            "NORMAL       1348\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Criação do dataframe de treino\n",
        "rows_train = []\n",
        "train_path = \"/content/data_train_tratado/chest_xray_tratado/train\"\n",
        "\n",
        "df_train = create_df(rows_train, train_path)\n",
        "print(f\"Treino: {len(df_train)} imagens\")\n",
        "print(df_train[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_vz3P1qocEt",
        "outputId": "74909bec-99e2-4681-c136-f997e675f5c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S3Lh7Ha2rqbCgNPkxinIqdcQ_L_qpS_U\n",
            "To: /content/chest_xray_weight.pkl\n",
            "100%|██████████| 38.0/38.0 [00:00<00:00, 175kB/s]\n"
          ]
        }
      ],
      "source": [
        "# Carregamento dos pesos\n",
        "weight_id = \"1S3Lh7Ha2rqbCgNPkxinIqdcQ_L_qpS_U\"\n",
        "\n",
        "gdown.download(\n",
        "    f\"https://drive.google.com/uc?id={weight_id}\",\n",
        "    \"/content/chest_xray_weight.pkl\",\n",
        "    quiet=False,\n",
        "    )\n",
        "\n",
        "with open('/content/chest_xray_weight.pkl', 'rb') as f:\n",
        "    class_weights = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz_DxlWS2gzr"
      },
      "source": [
        "###Definição de funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2KE2L6FR5nGl"
      },
      "outputs": [],
      "source": [
        "# Função de normalização dos pixels + conversão para grayscale\n",
        "def carregar_imagem(filepath):\n",
        "    if hasattr(filepath, 'numpy'):\n",
        "        filepath = filepath.numpy().decode('utf-8')\n",
        "\n",
        "    img = Image.open(filepath).convert('L')\n",
        "    img = ImageOps.pad(img, (224, 224), color=0)\n",
        "    arr = np.array(img, dtype=np.float32)\n",
        "    arr = arr / 255.0\n",
        "    arr = (arr - 0.485) / 0.229\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VGf0yPQv-dM_"
      },
      "outputs": [],
      "source": [
        "# Função de augmentação (auxílio ao OverSampling)\n",
        "def augmentar_imagem(img):\n",
        "    if random.random() > 0.5:\n",
        "        img = ImageOps.mirror(img)\n",
        "\n",
        "    angulo = random.uniform(-10, 10)\n",
        "    img = img.rotate(angulo, fillcolor=0)\n",
        "\n",
        "    margem = random.uniform(0.05, 0.10)\n",
        "    w, h = img.size\n",
        "    img = img.crop((\n",
        "        int(w * margem),\n",
        "        int(h * margem),\n",
        "        int(w * (1 - margem)),\n",
        "        int(h * (1 - margem)),\n",
        "    ))\n",
        "    img = img.resize((224, 224), Image.LANCZOS)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NcQlbVop-oSb"
      },
      "outputs": [],
      "source": [
        "# Uso apenas em casos de treino\n",
        "# As duas funções \"juntas\"\n",
        "def carregar_com_augmentation(filepath):\n",
        "    if hasattr(filepath, 'numpy'):\n",
        "        filepath = filepath.numpy().decode('utf-8')\n",
        "\n",
        "    img = Image.open(filepath).convert('L')\n",
        "    img = augmentar_imagem(img)\n",
        "    arr = np.array(img, dtype=np.float32)\n",
        "    arr = arr / 255.0\n",
        "    arr = (arr - 0.485) / 0.229\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S0gQpVvSQoSE"
      },
      "outputs": [],
      "source": [
        "# Gerador para carregar uma parte do dataset por vez e usar menos memória RAM\n",
        "def criar_gerador(df, batch_size=32, augmentar=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (df['filepath'].values, df['label_bin'].values),\n",
        "        )\n",
        "\n",
        "    def carregar_batch(filepath, label):\n",
        "        img = tf.py_function(\n",
        "            func = carregar_com_augmentation if augmentar else carregar_imagem,\n",
        "            inp  = [filepath],\n",
        "            Tout = tf.float32,\n",
        "            )\n",
        "        img.set_shape((224, 224, 3))\n",
        "        return img, label\n",
        "\n",
        "    dataset = dataset.map(carregar_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6QjvGHHI-Vi"
      },
      "source": [
        "###Arquitetura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ze_VozIJDNy"
      },
      "source": [
        "Com o intuito de ter um bom desempenho, foi escolhida a rede convolucional DenseNet121 para compor a modelagem do projeto. Essa decisão levou em conta a popularidade da rede CNN em projetos do eixo médico, tendo bom desempenhos em métricas de Recall e AUC-ROC com aplicação na área de visão computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oUDzbOci_iro",
        "outputId": "e92aaf35-22b6-4d75-f6d4-1dcd0b1bfa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Função da arquitetura (personalizável)\n",
        "def construir_modelo():\n",
        "    base_model = DenseNet121(\n",
        "        # Os pesos são públicos, respeitando as regras de uso de transfer learning\n",
        "        weights = 'imagenet',\n",
        "        include_top = False,\n",
        "        input_shape = (224, 224, 3),\n",
        "        )\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "model, base_model = construir_modelo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vvYFeO6aLbAp"
      },
      "outputs": [],
      "source": [
        "# Função para compilar\n",
        "def compilar_modelo(model, learning_rate):\n",
        "    model.compile(\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss      = 'binary_crossentropy',\n",
        "        metrics   = [\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6sK73B7KKIg"
      },
      "source": [
        "###Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41tQcwNLQSPB"
      },
      "source": [
        "Na primeira tentativa de rodar o código abaixo, ele carregava todas as imagens de uma vez, o que consumiu toda a memória RAM disponível. A solução achada foi criar um meio de carregamento em lotes e temporário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QccugXZsKlFC",
        "outputId": "f90eec0f-c7a4-49cc-e273-0ef024f40ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD 1 / 5\n",
            "Treino: 4164 imagens\n",
            "Val: 1042 imagens\n",
            "Carregando imagens...\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 472ms/step - auc: 0.5646 - loss: 1.3088 - precision: 0.5377 - recall: 0.4361 - val_auc: 0.5000 - val_loss: 2.0026 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.4042 - loss: 2.4240 - precision: 0.4178 - recall: 0.4936 - val_auc: 0.5764 - val_loss: 1.5370 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.4416 - loss: 1.9145 - precision: 0.4253 - recall: 0.5500 - val_auc: 0.7748 - val_loss: 1.3457 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.4957 - loss: 1.5160 - precision: 0.4488 - recall: 0.5792 - val_auc: 0.8223 - val_loss: 1.2630 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5393 - loss: 1.3005 - precision: 0.4691 - recall: 0.6038 - val_auc: 0.9151 - val_loss: 1.1053 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5672 - loss: 1.1593 - precision: 0.4799 - recall: 0.6314 - val_auc: 0.8209 - val_loss: 1.2741 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - auc: 0.5642 - loss: 1.2629 - precision: 0.4809 - recall: 0.6379\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - auc: 0.5690 - loss: 1.2516 - precision: 0.4865 - recall: 0.6427 - val_auc: 0.8261 - val_loss: 1.2674 - val_precision: 0.7409 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5442 - loss: 1.4741 - precision: 0.4423 - recall: 0.7123 - val_auc: 0.9643 - val_loss: 0.7358 - val_precision: 0.7423 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.6571 - loss: 0.7933 - precision: 0.5060 - recall: 0.6969 - val_auc: 0.9581 - val_loss: 0.7877 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - auc: 0.6621 - loss: 0.7739 - precision: 0.5126 - recall: 0.6966\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.6662 - loss: 0.7679 - precision: 0.5180 - recall: 0.7007 - val_auc: 0.9564 - val_loss: 0.8105 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.6767 - loss: 0.8408 - precision: 0.4930 - recall: 0.7261 - val_auc: 0.9704 - val_loss: 0.5917 - val_precision: 0.7502 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.7046 - loss: 0.6178 - precision: 0.5331 - recall: 0.7251 - val_auc: 0.9714 - val_loss: 0.5910 - val_precision: 0.7502 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.6990 - loss: 0.6204 - precision: 0.5389 - recall: 0.7188 - val_auc: 0.9724 - val_loss: 0.5927 - val_precision: 0.7510 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - auc: 0.7054 - loss: 0.5803 - precision: 0.5416 - recall: 0.7176 - val_auc: 0.9713 - val_loss: 0.6043 - val_precision: 0.7495 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - auc: 0.7024 - loss: 0.5818 - precision: 0.5436 - recall: 0.7132\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - auc: 0.7063 - loss: 0.5777 - precision: 0.5489 - recall: 0.7172 - val_auc: 0.9676 - val_loss: 0.6223 - val_precision: 0.7495 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 503ms/step - auc: 0.3282 - loss: 2.0869 - precision: 0.3916 - recall: 0.6932 - val_auc: 0.9692 - val_loss: 0.3995 - val_precision: 0.7619 - val_recall: 0.9987 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - auc: 0.3120 - loss: 1.9096 - precision: 0.3911 - recall: 0.7011 - val_auc: 0.9606 - val_loss: 0.4436 - val_precision: 0.7473 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - auc: 0.2948 - loss: 1.8159 - precision: 0.3896 - recall: 0.7182\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 186ms/step - auc: 0.2971 - loss: 1.8025 - precision: 0.3949 - recall: 0.7221 - val_auc: 0.9532 - val_loss: 0.4748 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - auc: 0.3440 - loss: 1.7187 - precision: 0.3978 - recall: 0.7393 - val_auc: 0.9491 - val_loss: 0.4755 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
            "Fold 1 concluído:\n",
            "  AUC-ROC: 0.9692\n",
            "  Recall:  0.9987\n",
            "FOLD 2 / 5\n",
            "Treino: 4165 imagens\n",
            "Val: 1041 imagens\n",
            "Carregando imagens...\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 466ms/step - auc: 0.5886 - loss: 1.2199 - precision: 0.5838 - recall: 0.4406 - val_auc: 0.5000 - val_loss: 2.3028 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - auc: 0.3983 - loss: 2.8264 - precision: 0.4106 - recall: 0.4832 - val_auc: 0.5974 - val_loss: 1.5461 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - auc: 0.4543 - loss: 1.8870 - precision: 0.4345 - recall: 0.5413 - val_auc: 0.8212 - val_loss: 1.2488 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5132 - loss: 1.4710 - precision: 0.4531 - recall: 0.5806 - val_auc: 0.7479 - val_loss: 1.3925 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 182ms/step - auc: 0.5155 - loss: 1.5285 - precision: 0.4651 - recall: 0.6062 - val_auc: 0.9056 - val_loss: 1.0739 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.5635 - loss: 1.1910 - precision: 0.4782 - recall: 0.6361 - val_auc: 0.9225 - val_loss: 1.0251 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - auc: 0.6002 - loss: 1.0250 - precision: 0.5001 - recall: 0.6528 - val_auc: 0.8940 - val_loss: 1.0826 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - auc: 0.6046 - loss: 1.0417 - precision: 0.4985 - recall: 0.6528\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - auc: 0.6092 - loss: 1.0326 - precision: 0.5041 - recall: 0.6574 - val_auc: 0.9206 - val_loss: 1.0263 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - auc: 0.5941 - loss: 1.2018 - precision: 0.4573 - recall: 0.7200 - val_auc: 0.9637 - val_loss: 0.6476 - val_precision: 0.7421 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.6687 - loss: 0.7361 - precision: 0.5173 - recall: 0.7122 - val_auc: 0.9609 - val_loss: 0.7107 - val_precision: 0.7413 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - auc: 0.6677 - loss: 0.7377 - precision: 0.5163 - recall: 0.6984\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - auc: 0.6718 - loss: 0.7321 - precision: 0.5217 - recall: 0.7025 - val_auc: 0.9601 - val_loss: 0.7261 - val_precision: 0.7421 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.6853 - loss: 0.7996 - precision: 0.4930 - recall: 0.7312 - val_auc: 0.9698 - val_loss: 0.5303 - val_precision: 0.7566 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - auc: 0.7021 - loss: 0.6045 - precision: 0.5319 - recall: 0.7189 - val_auc: 0.9712 - val_loss: 0.5286 - val_precision: 0.7581 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.7085 - loss: 0.5619 - precision: 0.5425 - recall: 0.7196 - val_auc: 0.9692 - val_loss: 0.5369 - val_precision: 0.7574 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - auc: 0.7095 - loss: 0.5387 - precision: 0.5484 - recall: 0.7228\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.7134 - loss: 0.5350 - precision: 0.5536 - recall: 0.7266 - val_auc: 0.9679 - val_loss: 0.5543 - val_precision: 0.7574 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 499ms/step - auc: 0.3377 - loss: 1.9581 - precision: 0.3940 - recall: 0.7114 - val_auc: 0.9709 - val_loss: 0.3956 - val_precision: 0.7559 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 195ms/step - auc: 0.3139 - loss: 1.8074 - precision: 0.3959 - recall: 0.7310 - val_auc: 0.9661 - val_loss: 0.4429 - val_precision: 0.7435 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - auc: 0.3107 - loss: 1.6752 - precision: 0.3916 - recall: 0.7319\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - auc: 0.3129 - loss: 1.6630 - precision: 0.3969 - recall: 0.7358 - val_auc: 0.9564 - val_loss: 0.4911 - val_precision: 0.7413 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - auc: 0.3517 - loss: 1.5850 - precision: 0.3988 - recall: 0.7467 - val_auc: 0.9532 - val_loss: 0.4937 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
            "Fold 2 concluído:\n",
            "  AUC-ROC: 0.9709\n",
            "  Recall:  1.0000\n",
            "FOLD 3 / 5\n",
            "Treino: 4165 imagens\n",
            "Val: 1041 imagens\n",
            "Carregando imagens...\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 432ms/step - auc: 0.6136 - loss: 1.3451 - precision: 0.6408 - recall: 0.4237 - val_auc: 0.5000 - val_loss: 2.3574 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - auc: 0.3821 - loss: 3.0433 - precision: 0.4121 - recall: 0.4721 - val_auc: 0.5317 - val_loss: 1.6459 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 181ms/step - auc: 0.4247 - loss: 2.0742 - precision: 0.4261 - recall: 0.5424 - val_auc: 0.8211 - val_loss: 1.2495 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5039 - loss: 1.4745 - precision: 0.4492 - recall: 0.5833 - val_auc: 0.8488 - val_loss: 1.2256 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.5372 - loss: 1.3402 - precision: 0.4669 - recall: 0.6039 - val_auc: 0.8525 - val_loss: 1.2241 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5575 - loss: 1.2548 - precision: 0.4800 - recall: 0.6216 - val_auc: 0.9038 - val_loss: 1.0733 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.5885 - loss: 1.0683 - precision: 0.4859 - recall: 0.6319 - val_auc: 0.9016 - val_loss: 1.0724 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - auc: 0.5992 - loss: 1.0452 - precision: 0.4885 - recall: 0.6436\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - auc: 0.6039 - loss: 1.0362 - precision: 0.4940 - recall: 0.6483 - val_auc: 0.8508 - val_loss: 1.2090 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.5487 - loss: 1.4348 - precision: 0.4468 - recall: 0.7113 - val_auc: 0.9600 - val_loss: 0.6798 - val_precision: 0.7456 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - auc: 0.6628 - loss: 0.7697 - precision: 0.5155 - recall: 0.6949 - val_auc: 0.9598 - val_loss: 0.7474 - val_precision: 0.7456 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - auc: 0.6637 - loss: 0.7622 - precision: 0.5147 - recall: 0.6891\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.6678 - loss: 0.7563 - precision: 0.5201 - recall: 0.6933 - val_auc: 0.9600 - val_loss: 0.7457 - val_precision: 0.7456 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.6784 - loss: 0.8182 - precision: 0.4939 - recall: 0.7255 - val_auc: 0.9696 - val_loss: 0.5601 - val_precision: 0.7559 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.7023 - loss: 0.6042 - precision: 0.5321 - recall: 0.7183 - val_auc: 0.9715 - val_loss: 0.5494 - val_precision: 0.7581 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.7064 - loss: 0.5784 - precision: 0.5468 - recall: 0.7203 - val_auc: 0.9689 - val_loss: 0.5771 - val_precision: 0.7574 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - auc: 0.6964 - loss: 0.6103 - precision: 0.5409 - recall: 0.7101\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.7003 - loss: 0.6060 - precision: 0.5462 - recall: 0.7140 - val_auc: 0.9695 - val_loss: 0.5850 - val_precision: 0.7574 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 498ms/step - auc: 0.3299 - loss: 2.5885 - precision: 0.3953 - recall: 0.7326 - val_auc: 0.9695 - val_loss: 0.4840 - val_precision: 0.7493 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - auc: 0.2945 - loss: 2.2694 - precision: 0.3959 - recall: 0.7340 - val_auc: 0.9647 - val_loss: 0.4954 - val_precision: 0.7442 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - auc: 0.2936 - loss: 1.9076 - precision: 0.3899 - recall: 0.7266\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - auc: 0.2958 - loss: 1.8930 - precision: 0.3952 - recall: 0.7305 - val_auc: 0.9612 - val_loss: 0.4992 - val_precision: 0.7413 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 188ms/step - auc: 0.3540 - loss: 1.7458 - precision: 0.3983 - recall: 0.7439 - val_auc: 0.9581 - val_loss: 0.4967 - val_precision: 0.7406 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
            "Fold 3 concluído:\n",
            "  AUC-ROC: 0.9695\n",
            "  Recall:  1.0000\n",
            "FOLD 4 / 5\n",
            "Treino: 4165 imagens\n",
            "Val: 1041 imagens\n",
            "Carregando imagens...\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 418ms/step - auc: 0.5876 - loss: 1.2209 - precision: 0.5784 - recall: 0.4350 - val_auc: 0.4994 - val_loss: 2.3154 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.4005 - loss: 2.7515 - precision: 0.4129 - recall: 0.4796 - val_auc: 0.4994 - val_loss: 1.6992 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.4330 - loss: 2.0556 - precision: 0.4247 - recall: 0.5239 - val_auc: 0.7559 - val_loss: 1.3721 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - auc: 0.4939 - loss: 1.5847 - precision: 0.4452 - recall: 0.5784 - val_auc: 0.8814 - val_loss: 1.2005 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.5603 - loss: 1.2249 - precision: 0.4728 - recall: 0.6176 - val_auc: 0.8877 - val_loss: 1.1788 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.5759 - loss: 1.1583 - precision: 0.4901 - recall: 0.6334 - val_auc: 0.8993 - val_loss: 1.1280 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - auc: 0.6022 - loss: 1.0378 - precision: 0.4967 - recall: 0.6437 - val_auc: 0.8736 - val_loss: 1.1865 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - auc: 0.5975 - loss: 1.0935 - precision: 0.4938 - recall: 0.6391 - val_auc: 0.9026 - val_loss: 1.0662 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - auc: 0.6317 - loss: 0.9034 - precision: 0.5152 - recall: 0.6595 - val_auc: 0.8562 - val_loss: 1.2423 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - auc: 0.6209 - loss: 1.0180 - precision: 0.5028 - recall: 0.6489\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - auc: 0.6254 - loss: 1.0090 - precision: 0.5084 - recall: 0.6535 - val_auc: 0.8871 - val_loss: 1.1207 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - auc: 0.6249 - loss: 1.0864 - precision: 0.4673 - recall: 0.7164 - val_auc: 0.9620 - val_loss: 0.7077 - val_precision: 0.7423 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.6939 - loss: 0.6417 - precision: 0.5314 - recall: 0.7110 - val_auc: 0.9527 - val_loss: 0.7501 - val_precision: 0.7423 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - auc: 0.6869 - loss: 0.6534 - precision: 0.5326 - recall: 0.6969\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.6910 - loss: 0.6484 - precision: 0.5380 - recall: 0.7009 - val_auc: 0.9527 - val_loss: 0.7706 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 196ms/step - auc: 0.7034 - loss: 0.6984 - precision: 0.5170 - recall: 0.7280 - val_auc: 0.9677 - val_loss: 0.5675 - val_precision: 0.7546 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - auc: 0.7145 - loss: 0.5431 - precision: 0.5505 - recall: 0.7267 - val_auc: 0.9690 - val_loss: 0.5653 - val_precision: 0.7569 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 509ms/step - auc: 0.3579 - loss: 2.3486 - precision: 0.3934 - recall: 0.7077 - val_auc: 0.9702 - val_loss: 0.4279 - val_precision: 0.7659 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 197ms/step - auc: 0.3189 - loss: 2.1218 - precision: 0.3949 - recall: 0.7259 - val_auc: 0.9647 - val_loss: 0.4379 - val_precision: 0.7481 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - auc: 0.3119 - loss: 1.8755 - precision: 0.3903 - recall: 0.7266\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - auc: 0.3140 - loss: 1.8613 - precision: 0.3955 - recall: 0.7305 - val_auc: 0.9522 - val_loss: 0.4575 - val_precision: 0.7423 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - auc: 0.3478 - loss: 1.7150 - precision: 0.3991 - recall: 0.7449 - val_auc: 0.9471 - val_loss: 0.4562 - val_precision: 0.7423 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
            "Fold 4 concluído:\n",
            "  AUC-ROC: 0.9702\n",
            "  Recall:  1.0000\n",
            "FOLD 5 / 5\n",
            "Treino: 4165 imagens\n",
            "Val: 1041 imagens\n",
            "Carregando imagens...\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 439ms/step - auc: 0.6148 - loss: 1.4181 - precision: 0.6471 - recall: 0.4207 - val_auc: 0.5000 - val_loss: 2.0593 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - auc: 0.3995 - loss: 2.7804 - precision: 0.4106 - recall: 0.4819 - val_auc: 0.5511 - val_loss: 1.5569 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - auc: 0.4659 - loss: 1.9921 - precision: 0.4330 - recall: 0.5300 - val_auc: 0.8051 - val_loss: 1.2950 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - auc: 0.5118 - loss: 1.5463 - precision: 0.4586 - recall: 0.5725 - val_auc: 0.9180 - val_loss: 1.1027 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 188ms/step - auc: 0.5501 - loss: 1.3026 - precision: 0.4688 - recall: 0.5984 - val_auc: 0.9498 - val_loss: 1.0148 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.5799 - loss: 1.1336 - precision: 0.4834 - recall: 0.6378 - val_auc: 0.9235 - val_loss: 1.0862 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.5880 - loss: 1.1375 - precision: 0.4913 - recall: 0.6382 - val_auc: 0.9585 - val_loss: 0.9565 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - auc: 0.6159 - loss: 0.9844 - precision: 0.5060 - recall: 0.6441 - val_auc: 0.9489 - val_loss: 0.9942 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - auc: 0.6220 - loss: 0.9530 - precision: 0.5084 - recall: 0.6548\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.6265 - loss: 0.9447 - precision: 0.5139 - recall: 0.6593 - val_auc: 0.9322 - val_loss: 1.0560 - val_precision: 0.7416 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.6037 - loss: 1.1550 - precision: 0.4725 - recall: 0.7116 - val_auc: 0.9779 - val_loss: 0.6397 - val_precision: 0.7466 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - auc: 0.6839 - loss: 0.6925 - precision: 0.5268 - recall: 0.7092 - val_auc: 0.9759 - val_loss: 0.6833 - val_precision: 0.7466 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - auc: 0.6785 - loss: 0.6923 - precision: 0.5260 - recall: 0.7006\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - auc: 0.6826 - loss: 0.6870 - precision: 0.5313 - recall: 0.7046 - val_auc: 0.9732 - val_loss: 0.7089 - val_precision: 0.7459 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.6950 - loss: 0.7409 - precision: 0.5028 - recall: 0.7302 - val_auc: 0.9820 - val_loss: 0.5234 - val_precision: 0.7576 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.7112 - loss: 0.5573 - precision: 0.5450 - recall: 0.7220 - val_auc: 0.9825 - val_loss: 0.5200 - val_precision: 0.7583 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - auc: 0.7089 - loss: 0.5580 - precision: 0.5469 - recall: 0.7187 - val_auc: 0.9830 - val_loss: 0.5253 - val_precision: 0.7598 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 496ms/step - auc: 0.3461 - loss: 2.2911 - precision: 0.3937 - recall: 0.7231 - val_auc: 0.9741 - val_loss: 0.4353 - val_precision: 0.7561 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - auc: 0.3040 - loss: 2.0550 - precision: 0.3961 - recall: 0.7338 - val_auc: 0.9660 - val_loss: 0.4692 - val_precision: 0.7481 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m130/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - auc: 0.3017 - loss: 1.8090 - precision: 0.3925 - recall: 0.7364\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - auc: 0.3038 - loss: 1.7953 - precision: 0.3978 - recall: 0.7403 - val_auc: 0.9562 - val_loss: 0.4893 - val_precision: 0.7437 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - auc: 0.3494 - loss: 1.6686 - precision: 0.3974 - recall: 0.7425 - val_auc: 0.9507 - val_loss: 0.4910 - val_precision: 0.7430 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
            "Fold 5 concluído:\n",
            "  AUC-ROC: 0.9741\n",
            "  Recall:  1.0000\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "historico_auc = []\n",
        "historico_recall = []\n",
        "modelos_por_fold = []\n",
        "\n",
        "# O K = 5 foi escolhido como valor padrão\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train['label_bin'])):\n",
        "    print(f\"FOLD {fold + 1} / 5\")\n",
        "\n",
        "    # Um subconjunto de validação é criado a partir do conjunto de treino\n",
        "    df_fold_train = df_train.iloc[train_idx].reset_index(drop=True)\n",
        "    df_fold_val = df_train.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Treino: {len(df_fold_train)} imagens\")\n",
        "    print(f\"Val: {len(df_fold_val)} imagens\")\n",
        "\n",
        "    print(\"Carregando imagens...\")\n",
        "\n",
        "    # Augmention aplicada no conjunto de treino\n",
        "    train_gen = criar_gerador(df_fold_train, batch_size=32, augmentar=True)\n",
        "    val_gen = criar_gerador(df_fold_val, batch_size=32, augmentar=False)\n",
        "\n",
        "    # Passa pelas funções de criar modelo + compilação\n",
        "    model, base_model = construir_modelo()\n",
        "    model = compilar_modelo(model, learning_rate=1e-4)\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor = 'val_auc',\n",
        "            patience = 3,\n",
        "            mode = 'max',\n",
        "            restore_best_weights = True,\n",
        "            ),\n",
        "\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor = 'val_auc',\n",
        "            factor = 0.5,\n",
        "            patience = 2,\n",
        "            mode = 'max',\n",
        "            verbose = 1,\n",
        "            )]\n",
        "\n",
        "    # Feature extraction\n",
        "    print(\"Fase 1 — Feature extraction\")\n",
        "\n",
        "    history_fase1 = model.fit(\n",
        "        train_gen,\n",
        "        validation_data = val_gen,\n",
        "        epochs = 15,\n",
        "        class_weight = class_weights,\n",
        "        callbacks = callbacks,\n",
        "        verbose = 1,\n",
        "        )\n",
        "\n",
        "    # Fine tuning\n",
        "    print(\"Fase 2 — Fine tuning\")\n",
        "\n",
        "    # Descongela as últimas 45 camadas da DenseNet\n",
        "    for layer in base_model.layers[-45:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model = compilar_modelo(model, learning_rate=1e-5)\n",
        "\n",
        "    history_fase2 = model.fit(\n",
        "        train_gen,\n",
        "        validation_data = val_gen,\n",
        "        epochs = 20,\n",
        "        class_weight = class_weights,\n",
        "        callbacks = callbacks,\n",
        "        verbose = 1,\n",
        "        )\n",
        "\n",
        "    # Métricas\n",
        "    resultados = model.evaluate(val_gen, verbose=0)\n",
        "    auc_fold = resultados[1]\n",
        "    recall_fold = resultados[2]\n",
        "\n",
        "    historico_auc.append(auc_fold)\n",
        "    historico_recall.append(recall_fold)\n",
        "    modelos_por_fold.append(model)\n",
        "\n",
        "    print(f\"Fold {fold+1} concluído:\")\n",
        "    print(f\"  AUC-ROC: {auc_fold:.4f}\")\n",
        "    print(f\"  Recall:  {recall_fold:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHSd4I-SdKnE",
        "outputId": "9d03858b-d23a-4660-fb93-6cd052fec7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=============================================\n",
            "   RESULTADOS FINAIS — K-FOLD\n",
            "=============================================\n",
            "\n",
            "Fold 1: AUC=0.9692  Recall=0.9987\n",
            "Fold 2: AUC=0.9709  Recall=1.0000\n",
            "Fold 3: AUC=0.9695  Recall=1.0000\n",
            "Fold 4: AUC=0.9702  Recall=1.0000\n",
            "Fold 5: AUC=0.9741  Recall=1.0000\n",
            "\n",
            "📊 Médias:\n",
            "   AUC-ROC: 0.9708 ± 0.0018\n",
            "   Recall:  0.9997 ± 0.0005\n",
            "\n",
            "🏆 Melhor fold: Fold 5\n",
            "   AUC-ROC: 0.9741\n",
            "   Recall:  1.0000\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*45}\")\n",
        "print(f\"   RESULTADOS FINAIS — K-FOLD\")\n",
        "print(f\"{'='*45}\\n\")\n",
        "\n",
        "for i, (auc, recall) in enumerate(zip(historico_auc, historico_recall)):\n",
        "    print(f\"Fold {i+1}: AUC={auc:.4f}  Recall={recall:.4f}\")\n",
        "\n",
        "print(f\"\\n📊 Médias:\")\n",
        "print(f\"   AUC-ROC: {np.mean(historico_auc):.4f} ± {np.std(historico_auc):.4f}\")\n",
        "print(f\"   Recall:  {np.mean(historico_recall):.4f} ± {np.std(historico_recall):.4f}\")\n",
        "\n",
        "# Identifica o melhor fold pelo AUC\n",
        "melhor_fold = np.argmax(historico_auc)\n",
        "print(f\"\\n🏆 Melhor fold: Fold {melhor_fold+1}\")\n",
        "print(f\"   AUC-ROC: {historico_auc[melhor_fold]:.4f}\")\n",
        "print(f\"   Recall:  {historico_recall[melhor_fold]:.4f}\")\n",
        "\n",
        "# Seleciona o melhor modelo\n",
        "melhor_modelo = modelos_por_fold[melhor_fold]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ-x8ZwIcH76"
      },
      "source": [
        "###Treinamento final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_W6j2POGcHhS",
        "outputId": "32f7fc09-aecb-464e-ef5c-9f7c075af682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   TREINAMENTO FINAL — DATASET COMPLETO\n",
            "Fase 1 — Feature extraction\n",
            "Epoch 1/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 243ms/step - auc: 0.6256 - loss: 1.0960 - precision: 0.6354 - recall: 0.4823 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - auc: 0.4661 - loss: 2.8568 - precision: 0.4507 - recall: 0.4998 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 150ms/step - auc: 0.5035 - loss: 1.9252 - precision: 0.4539 - recall: 0.5331 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - auc: 0.5309 - loss: 1.6108 - precision: 0.4663 - recall: 0.5575 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - auc: 0.5770 - loss: 1.2165 - precision: 0.4875 - recall: 0.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 149ms/step - auc: 0.5879 - loss: 1.1859 - precision: 0.5006 - recall: 0.6179 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - auc: 0.6096 - loss: 1.0360 - precision: 0.5168 - recall: 0.6390 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 153ms/step - auc: 0.6310 - loss: 0.9070 - precision: 0.5205 - recall: 0.6483 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - auc: 0.6329 - loss: 0.9269 - precision: 0.5201 - recall: 0.6472 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 150ms/step - auc: 0.6503 - loss: 0.8266 - precision: 0.5354 - recall: 0.6513 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - auc: 0.6570 - loss: 0.7960 - precision: 0.5427 - recall: 0.6576 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - auc: 0.6619 - loss: 0.7742 - precision: 0.5509 - recall: 0.6674 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 149ms/step - auc: 0.6587 - loss: 0.8300 - precision: 0.5457 - recall: 0.6710 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - auc: 0.6787 - loss: 0.6917 - precision: 0.5551 - recall: 0.6799 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 150ms/step - auc: 0.6642 - loss: 0.8186 - precision: 0.5535 - recall: 0.6693 - learning_rate: 1.0000e-04\n",
            "\n",
            "Fase 2 — Fine tuning\n",
            "Epoch 1/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 267ms/step - auc: 0.3368 - loss: 3.5693 - precision: 0.3961 - recall: 0.7427 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 159ms/step - auc: 0.2992 - loss: 2.9415 - precision: 0.3956 - recall: 0.7407 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 156ms/step - auc: 0.2851 - loss: 2.3405 - precision: 0.3950 - recall: 0.7368 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 156ms/step - auc: 0.2913 - loss: 1.8769 - precision: 0.3949 - recall: 0.7338 - learning_rate: 1.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 157ms/step - auc: 0.3119 - loss: 1.6693 - precision: 0.3945 - recall: 0.7286 - learning_rate: 1.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 157ms/step - auc: 0.3293 - loss: 1.5563 - precision: 0.3957 - recall: 0.7347 - learning_rate: 1.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 157ms/step - auc: 0.3440 - loss: 1.4811 - precision: 0.3967 - recall: 0.7358 - learning_rate: 1.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 157ms/step - auc: 0.3619 - loss: 1.4214 - precision: 0.3967 - recall: 0.7352 - learning_rate: 1.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 157ms/step - auc: 0.3999 - loss: 1.3603 - precision: 0.3977 - recall: 0.7398 - learning_rate: 1.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 156ms/step - auc: 0.4128 - loss: 1.3295 - precision: 0.3990 - recall: 0.7371 - learning_rate: 1.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 158ms/step - auc: 0.4351 - loss: 1.2899 - precision: 0.3999 - recall: 0.7408 - learning_rate: 1.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 164ms/step - auc: 0.4607 - loss: 1.2421 - precision: 0.4012 - recall: 0.7396 - learning_rate: 1.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - auc: 0.4975 - loss: 1.1883 - precision: 0.4025 - recall: 0.7413 - learning_rate: 1.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 163ms/step - auc: 0.5225 - loss: 1.1594 - precision: 0.4049 - recall: 0.7394 - learning_rate: 1.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 161ms/step - auc: 0.5390 - loss: 1.1165 - precision: 0.4063 - recall: 0.7412 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 161ms/step - auc: 0.5689 - loss: 1.0582 - precision: 0.4104 - recall: 0.7418 - learning_rate: 1.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 160ms/step - auc: 0.6044 - loss: 0.9987 - precision: 0.4164 - recall: 0.7411 - learning_rate: 1.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 160ms/step - auc: 0.6310 - loss: 0.9397 - precision: 0.4226 - recall: 0.7405 - learning_rate: 1.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 161ms/step - auc: 0.6569 - loss: 0.8731 - precision: 0.4334 - recall: 0.7413 - learning_rate: 1.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 163ms/step - auc: 0.6731 - loss: 0.8291 - precision: 0.4405 - recall: 0.7411 - learning_rate: 1.0000e-05\n",
            "\n",
            "✅ Modelo final treinado!\n"
          ]
        }
      ],
      "source": [
        "print(\"   TREINAMENTO FINAL — DATASET COMPLETO\")\n",
        "\n",
        "train_gen_final = criar_gerador(df_train, batch_size=32, augmentar=True)\n",
        "\n",
        "model_final, base_model_final = construir_modelo()\n",
        "model_final = compilar_modelo(model_final, learning_rate=1e-4)\n",
        "\n",
        "# Callbacks ajustados — sem validação, usa apenas loss de treino\n",
        "callbacks_final = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor = 'loss',\n",
        "        factor = 0.5,\n",
        "        patience = 3,\n",
        "        mode = 'min',\n",
        "        verbose = 1,\n",
        "        )]\n",
        "\n",
        "# Fase 1 — Feature extraction\n",
        "print(\"Fase 1 — Feature extraction\")\n",
        "model_final.fit(\n",
        "    train_gen_final,\n",
        "    epochs = 15,\n",
        "    class_weight = class_weights,\n",
        "    callbacks = callbacks_final,\n",
        "    verbose = 1,\n",
        "    )\n",
        "\n",
        "# Fase 2 — Fine tuning\n",
        "print(\"\\nFase 2 — Fine tuning\")\n",
        "for layer in base_model_final.layers[-45:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_final = compilar_modelo(model_final, learning_rate=1e-5)\n",
        "\n",
        "model_final.fit(\n",
        "    train_gen_final,\n",
        "    epochs = 20,\n",
        "    class_weight = class_weights,\n",
        "    callbacks = callbacks_final,\n",
        "    verbose = 1,\n",
        "    )\n",
        "\n",
        "print(\"\\n✅ Modelo final treinado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FMdKONqtzDd8",
        "outputId": "5e2368f5-fa3d-47c2-f74d-f1c6af6d37b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modelo salvo em: modelo_pneumonia_final.keras\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_962f0e3e-23dd-410f-8e80-05190a6db8f4\", \"modelo_pneumonia_final.keras\", 40336534)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Salva o modelo treinado\n",
        "model_final.save('/content/modelo_pneumonia_final.keras')\n",
        "print(\"✅ Modelo salvo em: modelo_pneumonia_final.keras\")\n",
        "\n",
        "# Faz download\n",
        "from google.colab import files\n",
        "files.download('/content/modelo_pneumonia_final.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L33ofa6eUjl"
      },
      "source": [
        "###Predições"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "Og2QroLvzbQu",
        "outputId": "5dc29d84-e576-4f61-f1d8-7af1cc34d4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Predições concluídas!\n",
            "                                             filepath  \\\n",
            "0   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "1   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "2   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "3   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "4   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "5   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "6   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "7   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "8   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "9   /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "10  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "11  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "12  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "13  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "14  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "15  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "16  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "17  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "18  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "19  /content/data_test/chest_xray/test/NORMAL/NORM...   \n",
            "\n",
            "                    filename   label  label_bin  prob_pneumonia  \n",
            "0   NORMAL-2959018-0001.jpeg  NORMAL          0        0.978266  \n",
            "1   NORMAL-9441169-0001.jpeg  NORMAL          0        0.848161  \n",
            "2   NORMAL-8661138-0001.jpeg  NORMAL          0        0.908336  \n",
            "3   NORMAL-8750803-0001.jpeg  NORMAL          0        0.941261  \n",
            "4   NORMAL-6085151-0001.jpeg  NORMAL          0        0.975791  \n",
            "5   NORMAL-9275512-0001.jpeg  NORMAL          0        0.953931  \n",
            "6   NORMAL-3464500-0003.jpeg  NORMAL          0        0.938128  \n",
            "7    NORMAL-217318-0001.jpeg  NORMAL          0        0.978619  \n",
            "8    NORMAL-754920-0001.jpeg  NORMAL          0        0.962602  \n",
            "9   NORMAL-5356114-0001.jpeg  NORMAL          0        0.937371  \n",
            "10  NORMAL-1368583-0001.jpeg  NORMAL          0        0.929754  \n",
            "11  NORMAL-9217241-0001.jpeg  NORMAL          0        0.964251  \n",
            "12  NORMAL-5511958-0001.jpeg  NORMAL          0        0.939203  \n",
            "13  NORMAL-1763721-0001.jpeg  NORMAL          0        0.897344  \n",
            "14  NORMAL-1944537-0001.jpeg  NORMAL          0        0.954805  \n",
            "15  NORMAL-5661793-0001.jpeg  NORMAL          0        0.966846  \n",
            "16  NORMAL-7519498-0001.jpeg  NORMAL          0        0.951618  \n",
            "17  NORMAL-5513974-0001.jpeg  NORMAL          0        0.828359  \n",
            "18  NORMAL-7423096-0001.jpeg  NORMAL          0        0.982636  \n",
            "19   NORMAL-667173-0001.jpeg  NORMAL          0        0.936629  \n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1ae4f118-9d6a-48c7-8ead-695d476e749e\", \"predicoes_teste.csv\", 72382)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Análise do que foi treinado com base no teste\n",
        "predicoes = []\n",
        "\n",
        "for filepath in df_test['filepath']:\n",
        "    img = carregar_imagem(filepath)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    prob = model_final.predict(img, verbose=0)[0][0]\n",
        "    predicoes.append(prob)\n",
        "\n",
        "df_test['prob_pneumonia'] = predicoes\n",
        "\n",
        "print(\"\\n✅ Predições concluídas!\")\n",
        "print(df_test.head(20))\n",
        "\n",
        "df_test.to_csv('/content/predicoes_teste.csv', index=False)\n",
        "files.download('/content/predicoes_teste.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T-On97B1YOM",
        "outputId": "cbffaa07-be0d-46ce-8019-6bef58514fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contagem de labels:\n",
            "label\n",
            "PNEUMONIA    390\n",
            "NORMAL       234\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Estatísticas de prob_pneumonia:\n",
            "Mínima:  0.6867\n",
            "Máxima:  0.9977\n",
            "Média:   0.9537\n",
            "Mediana: 0.9625\n",
            "\n",
            "Classificadas como PNEUMONIA (prob >= 0.5): 624/624\n"
          ]
        }
      ],
      "source": [
        "# Verifica se TODAS as imagens são realmente NORMAL\n",
        "print(\"Contagem de labels:\")\n",
        "print(df_test['label'].value_counts())\n",
        "\n",
        "# Verifica a distribuição das probabilidades\n",
        "print(f\"\\nEstatísticas de prob_pneumonia:\")\n",
        "print(f\"Mínima:  {df_test['prob_pneumonia'].min():.4f}\")\n",
        "print(f\"Máxima:  {df_test['prob_pneumonia'].max():.4f}\")\n",
        "print(f\"Média:   {df_test['prob_pneumonia'].mean():.4f}\")\n",
        "print(f\"Mediana: {df_test['prob_pneumonia'].median():.4f}\")\n",
        "\n",
        "# Quantas o modelo classificaria como PNEUMONIA usando limiar 0.5?\n",
        "n_pneumonia = (df_test['prob_pneumonia'] >= 0.5).sum()\n",
        "print(f\"\\nClassificadas como PNEUMONIA (prob >= 0.5): {n_pneumonia}/{len(df_test)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
